{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'year', 'Life Ladder', 'Log GDP per capita',\n",
      "       'Social support', 'Healthy life expectancy at birth',\n",
      "       'Freedom to make life choices', 'Generosity',\n",
      "       'Perceptions of corruption', 'Positive affect', 'Negative affect',\n",
      "       'Confidence in national government', 'Democratic Quality',\n",
      "       'Delivery Quality', 'Standard deviation of ladder by country-year',\n",
      "       'Standard deviation/Mean of ladder by country-year',\n",
      "       'GINI index (World Bank estimate)',\n",
      "       'GINI index (World Bank estimate), average 2000-15',\n",
      "       'gini of household income reported in Gallup, by wp5-year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1  Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2  Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3  Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4  Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                         49.209663                      0.718114    0.181819   \n",
       "1                         49.624432                      0.678896    0.203614   \n",
       "2                         50.008961                      0.600127    0.137630   \n",
       "3                         50.367298                      0.495901    0.175329   \n",
       "4                         50.709263                      0.530935    0.247159   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0                   0.881686         0.517637         0.258195   \n",
       "1                   0.850035         0.583926         0.237092   \n",
       "2                   0.706766         0.618265         0.275324   \n",
       "3                   0.731109         0.611387         0.267175   \n",
       "4                   0.775620         0.710385         0.267919   \n",
       "\n",
       "   Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                           0.612072           -1.929690         -1.655084   \n",
       "1                           0.611545           -2.044093         -1.635025   \n",
       "2                           0.299357           -1.991810         -1.617176   \n",
       "3                           0.307386           -1.919018         -1.616221   \n",
       "4                           0.435440           -1.842996         -1.404078   \n",
       "\n",
       "   Standard deviation of ladder by country-year  \\\n",
       "0                                      1.774662   \n",
       "1                                      1.722688   \n",
       "2                                      1.878622   \n",
       "3                                      1.785360   \n",
       "4                                      1.798283   \n",
       "\n",
       "   Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                           0.476600   \n",
       "1                                           0.391362   \n",
       "2                                           0.394803   \n",
       "3                                           0.465942   \n",
       "4                                           0.475367   \n",
       "\n",
       "   GINI index (World Bank estimate)  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "\n",
       "   GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   gini of household income reported in Gallup, by wp5-year  \n",
       "0                                                NaN         \n",
       "1                                           0.441906         \n",
       "2                                           0.327318         \n",
       "3                                           0.336764         \n",
       "4                                           0.344540         "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(WHRDataSet_filename)# YOUR CODE HERE\n",
    "\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The data set I have chosen is the World Happiness Record data set.\n",
    "2. I will be predicting a country's life ladder score based on the score of the other features, such as log gdp per capita, social support, healthy life expectancy at birth, etc. The label is the column \"Life Ladder\"\n",
    "3. This is a supervised learning problem because I have identified a label column and will be training my model based on that label. This is a regression problem because the label is a numerical value.\n",
    "4. My initial set of features will be life ladder, log gdp per capita, social support, healthy life expectancy at birth, freedom to make life choices, perceptions of corruption, positive and negative affect, confidence in national government, democratic quality, delivery quality, GINI Index (World Bank Estimate), and GINI of household income reported in Gallup, by wp5-year.\n",
    "5. This is an important problem because it could help countries identify what increases or worsens citizens' quality of life.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "      <th>label_life_ladder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.820743</td>\n",
       "      <td>5.433676</td>\n",
       "      <td>9.220822</td>\n",
       "      <td>0.810669</td>\n",
       "      <td>62.249887</td>\n",
       "      <td>0.728975</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.753622</td>\n",
       "      <td>0.708969</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.480207</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>2.003501</td>\n",
       "      <td>0.387271</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>5.435275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.419787</td>\n",
       "      <td>1.121017</td>\n",
       "      <td>1.173750</td>\n",
       "      <td>0.118872</td>\n",
       "      <td>7.937689</td>\n",
       "      <td>0.144051</td>\n",
       "      <td>0.159939</td>\n",
       "      <td>0.180110</td>\n",
       "      <td>0.107021</td>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.180621</td>\n",
       "      <td>0.824041</td>\n",
       "      <td>0.925759</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.119007</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.078834</td>\n",
       "      <td>0.092575</td>\n",
       "      <td>1.112060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>2.661718</td>\n",
       "      <td>6.377396</td>\n",
       "      <td>0.290184</td>\n",
       "      <td>37.766476</td>\n",
       "      <td>0.257534</td>\n",
       "      <td>-0.322952</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.362498</td>\n",
       "      <td>0.083426</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>-2.448228</td>\n",
       "      <td>-2.144974</td>\n",
       "      <td>0.863034</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.228833</td>\n",
       "      <td>0.223470</td>\n",
       "      <td>3.174264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>4.606351</td>\n",
       "      <td>8.330659</td>\n",
       "      <td>0.749794</td>\n",
       "      <td>57.344959</td>\n",
       "      <td>0.635676</td>\n",
       "      <td>-0.108292</td>\n",
       "      <td>0.702761</td>\n",
       "      <td>0.622581</td>\n",
       "      <td>0.204680</td>\n",
       "      <td>0.348685</td>\n",
       "      <td>-0.713479</td>\n",
       "      <td>-0.671931</td>\n",
       "      <td>1.737934</td>\n",
       "      <td>0.309722</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.327250</td>\n",
       "      <td>0.386856</td>\n",
       "      <td>4.606351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>5.332600</td>\n",
       "      <td>9.361684</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>63.763542</td>\n",
       "      <td>0.744320</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>0.798041</td>\n",
       "      <td>0.715595</td>\n",
       "      <td>0.252504</td>\n",
       "      <td>0.480207</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>-0.084389</td>\n",
       "      <td>1.960345</td>\n",
       "      <td>0.369751</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>5.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.271025</td>\n",
       "      <td>10.167549</td>\n",
       "      <td>0.904097</td>\n",
       "      <td>68.064693</td>\n",
       "      <td>0.841122</td>\n",
       "      <td>0.086098</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.310713</td>\n",
       "      <td>0.593869</td>\n",
       "      <td>0.504140</td>\n",
       "      <td>0.606049</td>\n",
       "      <td>2.215920</td>\n",
       "      <td>0.451833</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.429250</td>\n",
       "      <td>0.480072</td>\n",
       "      <td>6.271025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>8.018934</td>\n",
       "      <td>11.770276</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>76.536362</td>\n",
       "      <td>0.985178</td>\n",
       "      <td>0.677773</td>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>0.704590</td>\n",
       "      <td>0.993604</td>\n",
       "      <td>1.540097</td>\n",
       "      <td>2.184725</td>\n",
       "      <td>3.527820</td>\n",
       "      <td>1.022769</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.961435</td>\n",
       "      <td>7.614929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "count  1562.000000  1562.000000         1562.000000     1562.000000   \n",
       "mean   2011.820743     5.433676            9.220822        0.810669   \n",
       "std       3.419787     1.121017            1.173750        0.118872   \n",
       "min    2005.000000     2.661718            6.377396        0.290184   \n",
       "25%    2009.000000     4.606351            8.330659        0.749794   \n",
       "50%    2012.000000     5.332600            9.361684        0.831776   \n",
       "75%    2015.000000     6.271025           10.167549        0.904097   \n",
       "max    2017.000000     8.018934           11.770276        0.987343   \n",
       "\n",
       "       Healthy life expectancy at birth  Freedom to make life choices  \\\n",
       "count                       1562.000000                   1562.000000   \n",
       "mean                          62.249887                      0.728975   \n",
       "std                            7.937689                      0.144051   \n",
       "min                           37.766476                      0.257534   \n",
       "25%                           57.344959                      0.635676   \n",
       "50%                           63.763542                      0.744320   \n",
       "75%                           68.064693                      0.841122   \n",
       "max                           76.536362                      0.985178   \n",
       "\n",
       "        Generosity  Perceptions of corruption  Positive affect  \\\n",
       "count  1562.000000                1562.000000      1562.000000   \n",
       "mean      0.000079                   0.753622         0.708969   \n",
       "std       0.159939                   0.180110         0.107021   \n",
       "min      -0.322952                   0.035198         0.362498   \n",
       "25%      -0.108292                   0.702761         0.622581   \n",
       "50%      -0.011797                   0.798041         0.715595   \n",
       "75%       0.086098                   0.874675         0.799524   \n",
       "max       0.677773                   0.983276         0.943621   \n",
       "\n",
       "       Negative affect  Confidence in national government  Democratic Quality  \\\n",
       "count      1562.000000                        1562.000000         1562.000000   \n",
       "mean          0.263171                           0.480207           -0.126617   \n",
       "std           0.083682                           0.180621            0.824041   \n",
       "min           0.083426                           0.068769           -2.448228   \n",
       "25%           0.204680                           0.348685           -0.713479   \n",
       "50%           0.252504                           0.480207           -0.126617   \n",
       "75%           0.310713                           0.593869            0.504140   \n",
       "max           0.704590                           0.993604            1.540097   \n",
       "\n",
       "       Delivery Quality  Standard deviation of ladder by country-year  \\\n",
       "count       1562.000000                                   1562.000000   \n",
       "mean           0.004947                                      2.003501   \n",
       "std            0.925759                                      0.379684   \n",
       "min           -2.144974                                      0.863034   \n",
       "25%           -0.671931                                      1.737934   \n",
       "50%           -0.084389                                      1.960345   \n",
       "75%            0.606049                                      2.215920   \n",
       "max            2.184725                                      3.527820   \n",
       "\n",
       "       Standard deviation/Mean of ladder by country-year  \\\n",
       "count                                        1562.000000   \n",
       "mean                                            0.387271   \n",
       "std                                             0.119007   \n",
       "min                                             0.133908   \n",
       "25%                                             0.309722   \n",
       "50%                                             0.369751   \n",
       "75%                                             0.451833   \n",
       "max                                             1.022769   \n",
       "\n",
       "       GINI index (World Bank estimate)  \\\n",
       "count                       1562.000000   \n",
       "mean                           0.372846   \n",
       "std                            0.052884   \n",
       "min                            0.241000   \n",
       "25%                            0.372846   \n",
       "50%                            0.372846   \n",
       "75%                            0.372846   \n",
       "max                            0.648000   \n",
       "\n",
       "       GINI index (World Bank estimate), average 2000-15  \\\n",
       "count                                        1562.000000   \n",
       "mean                                            0.386948   \n",
       "std                                             0.078834   \n",
       "min                                             0.228833   \n",
       "25%                                             0.327250   \n",
       "50%                                             0.386948   \n",
       "75%                                             0.429250   \n",
       "max                                             0.626000   \n",
       "\n",
       "       gini of household income reported in Gallup, by wp5-year  \\\n",
       "count                                        1562.000000          \n",
       "mean                                            0.445204          \n",
       "std                                             0.092575          \n",
       "min                                             0.223470          \n",
       "25%                                             0.386856          \n",
       "50%                                             0.445204          \n",
       "75%                                             0.480072          \n",
       "max                                             0.961435          \n",
       "\n",
       "       label_life_ladder  \n",
       "count        1562.000000  \n",
       "mean            5.435275  \n",
       "std             1.112060  \n",
       "min             3.174264  \n",
       "25%             4.606351  \n",
       "50%             5.332600  \n",
       "75%             6.271025  \n",
       "max             7.614929  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "      <th>label_life_ladder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>3.723590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.441906</td>\n",
       "      <td>4.401778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>4.758381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.336764</td>\n",
       "      <td>3.831719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.344540</td>\n",
       "      <td>3.782938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.690188</td>\n",
       "      <td>7.565154</td>\n",
       "      <td>0.799274</td>\n",
       "      <td>48.949745</td>\n",
       "      <td>0.575884</td>\n",
       "      <td>-0.076716</td>\n",
       "      <td>0.830937</td>\n",
       "      <td>0.711885</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>0.527755</td>\n",
       "      <td>-1.026085</td>\n",
       "      <td>-1.526321</td>\n",
       "      <td>1.964805</td>\n",
       "      <td>0.418918</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.555439</td>\n",
       "      <td>4.690188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.184451</td>\n",
       "      <td>7.562753</td>\n",
       "      <td>0.765839</td>\n",
       "      <td>50.051235</td>\n",
       "      <td>0.642034</td>\n",
       "      <td>-0.045885</td>\n",
       "      <td>0.820217</td>\n",
       "      <td>0.725214</td>\n",
       "      <td>0.239111</td>\n",
       "      <td>0.566209</td>\n",
       "      <td>-0.985267</td>\n",
       "      <td>-1.484067</td>\n",
       "      <td>2.079248</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.601080</td>\n",
       "      <td>4.184451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.703191</td>\n",
       "      <td>7.556052</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>50.925652</td>\n",
       "      <td>0.667193</td>\n",
       "      <td>-0.094585</td>\n",
       "      <td>0.810457</td>\n",
       "      <td>0.715079</td>\n",
       "      <td>0.178861</td>\n",
       "      <td>0.590012</td>\n",
       "      <td>-0.893078</td>\n",
       "      <td>-1.357514</td>\n",
       "      <td>2.198865</td>\n",
       "      <td>0.593776</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.655137</td>\n",
       "      <td>3.703191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.735400</td>\n",
       "      <td>7.538829</td>\n",
       "      <td>0.768425</td>\n",
       "      <td>51.800068</td>\n",
       "      <td>0.732971</td>\n",
       "      <td>-0.065283</td>\n",
       "      <td>0.723612</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.208555</td>\n",
       "      <td>0.699344</td>\n",
       "      <td>-0.863044</td>\n",
       "      <td>-1.371214</td>\n",
       "      <td>2.776363</td>\n",
       "      <td>0.743257</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.596690</td>\n",
       "      <td>3.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.638300</td>\n",
       "      <td>7.538187</td>\n",
       "      <td>0.754147</td>\n",
       "      <td>52.674484</td>\n",
       "      <td>0.752826</td>\n",
       "      <td>-0.066005</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.806428</td>\n",
       "      <td>0.224051</td>\n",
       "      <td>0.682647</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>2.656848</td>\n",
       "      <td>0.730244</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.581484</td>\n",
       "      <td>3.638300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1562 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0     Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1     Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2     Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3     Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4     Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "...           ...   ...          ...                 ...             ...   \n",
       "1557     Zimbabwe  2013     4.690188            7.565154        0.799274   \n",
       "1558     Zimbabwe  2014     4.184451            7.562753        0.765839   \n",
       "1559     Zimbabwe  2015     3.703191            7.556052        0.735800   \n",
       "1560     Zimbabwe  2016     3.735400            7.538829        0.768425   \n",
       "1561     Zimbabwe  2017     3.638300            7.538187        0.754147   \n",
       "\n",
       "      Healthy life expectancy at birth  Freedom to make life choices  \\\n",
       "0                            49.209663                      0.718114   \n",
       "1                            49.624432                      0.678896   \n",
       "2                            50.008961                      0.600127   \n",
       "3                            50.367298                      0.495901   \n",
       "4                            50.709263                      0.530935   \n",
       "...                                ...                           ...   \n",
       "1557                         48.949745                      0.575884   \n",
       "1558                         50.051235                      0.642034   \n",
       "1559                         50.925652                      0.667193   \n",
       "1560                         51.800068                      0.732971   \n",
       "1561                         52.674484                      0.752826   \n",
       "\n",
       "      Generosity  Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0       0.181819                   0.881686         0.517637         0.258195   \n",
       "1       0.203614                   0.850035         0.583926         0.237092   \n",
       "2       0.137630                   0.706766         0.618265         0.275324   \n",
       "3       0.175329                   0.731109         0.611387         0.267175   \n",
       "4       0.247159                   0.775620         0.710385         0.267919   \n",
       "...          ...                        ...              ...              ...   \n",
       "1557   -0.076716                   0.830937         0.711885         0.182288   \n",
       "1558   -0.045885                   0.820217         0.725214         0.239111   \n",
       "1559   -0.094585                   0.810457         0.715079         0.178861   \n",
       "1560   -0.065283                   0.723612         0.737636         0.208555   \n",
       "1561   -0.066005                   0.751208         0.806428         0.224051   \n",
       "\n",
       "      Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                              0.612072           -1.929690         -1.655084   \n",
       "1                              0.611545           -2.044093         -1.635025   \n",
       "2                              0.299357           -1.991810         -1.617176   \n",
       "3                              0.307386           -1.919018         -1.616221   \n",
       "4                              0.435440           -1.842996         -1.404078   \n",
       "...                                 ...                 ...               ...   \n",
       "1557                           0.527755           -1.026085         -1.526321   \n",
       "1558                           0.566209           -0.985267         -1.484067   \n",
       "1559                           0.590012           -0.893078         -1.357514   \n",
       "1560                           0.699344           -0.863044         -1.371214   \n",
       "1561                           0.682647           -0.126617          0.004947   \n",
       "\n",
       "      Standard deviation of ladder by country-year  \\\n",
       "0                                         1.774662   \n",
       "1                                         1.722688   \n",
       "2                                         1.878622   \n",
       "3                                         1.785360   \n",
       "4                                         1.798283   \n",
       "...                                            ...   \n",
       "1557                                      1.964805   \n",
       "1558                                      2.079248   \n",
       "1559                                      2.198865   \n",
       "1560                                      2.776363   \n",
       "1561                                      2.656848   \n",
       "\n",
       "      Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                              0.476600   \n",
       "1                                              0.391362   \n",
       "2                                              0.394803   \n",
       "3                                              0.465942   \n",
       "4                                              0.475367   \n",
       "...                                                 ...   \n",
       "1557                                           0.418918   \n",
       "1558                                           0.496899   \n",
       "1559                                           0.593776   \n",
       "1560                                           0.743257   \n",
       "1561                                           0.730244   \n",
       "\n",
       "      GINI index (World Bank estimate)  \\\n",
       "0                             0.372846   \n",
       "1                             0.372846   \n",
       "2                             0.372846   \n",
       "3                             0.372846   \n",
       "4                             0.372846   \n",
       "...                                ...   \n",
       "1557                          0.372846   \n",
       "1558                          0.372846   \n",
       "1559                          0.372846   \n",
       "1560                          0.372846   \n",
       "1561                          0.372846   \n",
       "\n",
       "      GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                              0.386948   \n",
       "1                                              0.386948   \n",
       "2                                              0.386948   \n",
       "3                                              0.386948   \n",
       "4                                              0.386948   \n",
       "...                                                 ...   \n",
       "1557                                           0.432000   \n",
       "1558                                           0.432000   \n",
       "1559                                           0.432000   \n",
       "1560                                           0.432000   \n",
       "1561                                           0.432000   \n",
       "\n",
       "      gini of household income reported in Gallup, by wp5-year  \\\n",
       "0                                              0.445204          \n",
       "1                                              0.441906          \n",
       "2                                              0.327318          \n",
       "3                                              0.336764          \n",
       "4                                              0.344540          \n",
       "...                                                 ...          \n",
       "1557                                           0.555439          \n",
       "1558                                           0.601080          \n",
       "1559                                           0.655137          \n",
       "1560                                           0.596690          \n",
       "1561                                           0.581484          \n",
       "\n",
       "      label_life_ladder  \n",
       "0              3.723590  \n",
       "1              4.401778  \n",
       "2              4.758381  \n",
       "3              3.831719  \n",
       "4              3.782938  \n",
       "...                 ...  \n",
       "1557           4.690188  \n",
       "1558           4.184451  \n",
       "1559           3.703191  \n",
       "1560           3.735400  \n",
       "1561           3.638300  \n",
       "\n",
       "[1562 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#Replacing missing values\n",
    "nan_count = np.sum(df.isna(), axis = 0)\n",
    "nan_cols = nan_count > 0\n",
    "numerical_cols = (df.dtypes == 'int64') | (df.dtypes == 'float64')\n",
    "to_replace = nan_cols & numerical_cols\n",
    "for col in df.columns[to_replace]:\n",
    "    df[col].fillna(value=df[col].mean(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "      <th>label_life_ladder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.441906</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>4.758381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.336764</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.344540</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.572100</td>\n",
       "      <td>7.503376</td>\n",
       "      <td>0.483552</td>\n",
       "      <td>51.042980</td>\n",
       "      <td>0.577955</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.620585</td>\n",
       "      <td>0.273328</td>\n",
       "      <td>0.482847</td>\n",
       "      <td>-1.879709</td>\n",
       "      <td>-1.403036</td>\n",
       "      <td>1.223690</td>\n",
       "      <td>0.342569</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.304368</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.130896</td>\n",
       "      <td>7.484583</td>\n",
       "      <td>0.525568</td>\n",
       "      <td>51.370525</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.118579</td>\n",
       "      <td>0.871242</td>\n",
       "      <td>0.531691</td>\n",
       "      <td>0.374861</td>\n",
       "      <td>0.409048</td>\n",
       "      <td>-1.773257</td>\n",
       "      <td>-1.312503</td>\n",
       "      <td>1.395396</td>\n",
       "      <td>0.445686</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.413974</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.982855</td>\n",
       "      <td>7.466215</td>\n",
       "      <td>0.528597</td>\n",
       "      <td>51.693527</td>\n",
       "      <td>0.388928</td>\n",
       "      <td>0.094686</td>\n",
       "      <td>0.880638</td>\n",
       "      <td>0.553553</td>\n",
       "      <td>0.339276</td>\n",
       "      <td>0.260557</td>\n",
       "      <td>-1.844364</td>\n",
       "      <td>-1.291594</td>\n",
       "      <td>2.160618</td>\n",
       "      <td>0.542480</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.596918</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.220169</td>\n",
       "      <td>7.461401</td>\n",
       "      <td>0.559072</td>\n",
       "      <td>52.016529</td>\n",
       "      <td>0.522566</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.793246</td>\n",
       "      <td>0.564953</td>\n",
       "      <td>0.348332</td>\n",
       "      <td>0.324990</td>\n",
       "      <td>-1.917693</td>\n",
       "      <td>-1.432548</td>\n",
       "      <td>1.796219</td>\n",
       "      <td>0.425627</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.418629</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.661718</td>\n",
       "      <td>7.460144</td>\n",
       "      <td>0.490880</td>\n",
       "      <td>52.339527</td>\n",
       "      <td>0.427011</td>\n",
       "      <td>-0.106340</td>\n",
       "      <td>0.954393</td>\n",
       "      <td>0.496349</td>\n",
       "      <td>0.371326</td>\n",
       "      <td>0.261179</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>1.454051</td>\n",
       "      <td>0.546283</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.286599</td>\n",
       "      <td>4.606252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1  Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2  Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3  Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4  Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "5  Afghanistan  2013     3.572100            7.503376        0.483552   \n",
       "6  Afghanistan  2014     3.130896            7.484583        0.525568   \n",
       "7  Afghanistan  2015     3.982855            7.466215        0.528597   \n",
       "8  Afghanistan  2016     4.220169            7.461401        0.559072   \n",
       "9  Afghanistan  2017     2.661718            7.460144        0.490880   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                         49.209663                      0.718114    0.181819   \n",
       "1                         49.624432                      0.678896    0.203614   \n",
       "2                         50.008961                      0.600127    0.137630   \n",
       "3                         50.367298                      0.495901    0.175329   \n",
       "4                         50.709263                      0.530935    0.247159   \n",
       "5                         51.042980                      0.577955    0.074735   \n",
       "6                         51.370525                      0.508514    0.118579   \n",
       "7                         51.693527                      0.388928    0.094686   \n",
       "8                         52.016529                      0.522566    0.057072   \n",
       "9                         52.339527                      0.427011   -0.106340   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0                   0.881686         0.517637         0.258195   \n",
       "1                   0.850035         0.583926         0.237092   \n",
       "2                   0.706766         0.618265         0.275324   \n",
       "3                   0.731109         0.611387         0.267175   \n",
       "4                   0.775620         0.710385         0.267919   \n",
       "5                   0.823204         0.620585         0.273328   \n",
       "6                   0.871242         0.531691         0.374861   \n",
       "7                   0.880638         0.553553         0.339276   \n",
       "8                   0.793246         0.564953         0.348332   \n",
       "9                   0.954393         0.496349         0.371326   \n",
       "\n",
       "   Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                           0.612072           -1.929690         -1.655084   \n",
       "1                           0.611545           -2.044093         -1.635025   \n",
       "2                           0.299357           -1.991810         -1.617176   \n",
       "3                           0.307386           -1.919018         -1.616221   \n",
       "4                           0.435440           -1.842996         -1.404078   \n",
       "5                           0.482847           -1.879709         -1.403036   \n",
       "6                           0.409048           -1.773257         -1.312503   \n",
       "7                           0.260557           -1.844364         -1.291594   \n",
       "8                           0.324990           -1.917693         -1.432548   \n",
       "9                           0.261179           -0.126617          0.004947   \n",
       "\n",
       "   Standard deviation of ladder by country-year  \\\n",
       "0                                      1.774662   \n",
       "1                                      1.722688   \n",
       "2                                      1.878622   \n",
       "3                                      1.785360   \n",
       "4                                      1.798283   \n",
       "5                                      1.223690   \n",
       "6                                      1.395396   \n",
       "7                                      2.160618   \n",
       "8                                      1.796219   \n",
       "9                                      1.454051   \n",
       "\n",
       "   Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                           0.476600   \n",
       "1                                           0.391362   \n",
       "2                                           0.394803   \n",
       "3                                           0.465942   \n",
       "4                                           0.475367   \n",
       "5                                           0.342569   \n",
       "6                                           0.445686   \n",
       "7                                           0.542480   \n",
       "8                                           0.425627   \n",
       "9                                           0.546283   \n",
       "\n",
       "   GINI index (World Bank estimate)  \\\n",
       "0                          0.372846   \n",
       "1                          0.372846   \n",
       "2                          0.372846   \n",
       "3                          0.372846   \n",
       "4                          0.372846   \n",
       "5                          0.372846   \n",
       "6                          0.372846   \n",
       "7                          0.372846   \n",
       "8                          0.372846   \n",
       "9                          0.372846   \n",
       "\n",
       "   GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                           0.386948   \n",
       "1                                           0.386948   \n",
       "2                                           0.386948   \n",
       "3                                           0.386948   \n",
       "4                                           0.386948   \n",
       "5                                           0.386948   \n",
       "6                                           0.386948   \n",
       "7                                           0.386948   \n",
       "8                                           0.386948   \n",
       "9                                           0.386948   \n",
       "\n",
       "   gini of household income reported in Gallup, by wp5-year  label_life_ladder  \n",
       "0                                           0.445204                  4.606252  \n",
       "1                                           0.441906                  4.606252  \n",
       "2                                           0.327318                  4.758381  \n",
       "3                                           0.336764                  4.606252  \n",
       "4                                           0.344540                  4.606252  \n",
       "5                                           0.304368                  4.606252  \n",
       "6                                           0.413974                  4.606252  \n",
       "7                                           0.596918                  4.606252  \n",
       "8                                           0.418629                  4.606252  \n",
       "9                                           0.286599                  4.606252  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Detect and remove outliers\n",
    "import scipy.stats as stats\n",
    "df['label_life_ladder'] = stats.mstats.winsorize(df['Life Ladder'], limits=[0.25, 0.25])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 5.405399081148527\n",
      "median: 5.33259964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/numpy/core/fromnumeric.py:748: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: {mean}\".format(mean=df['label_life_ladder'].mean()))\n",
    "print(\"median: {med}\".format(med=df['label_life_ladder'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_life_ladder                                           1.00000\n",
       "Life Ladder                                                 0.94449\n",
       "Log GDP per capita                                          0.75467\n",
       "Healthy life expectancy at birth                            0.70915\n",
       "Social support                                              0.66250\n",
       "Delivery Quality                                            0.62369\n",
       "Democratic Quality                                          0.54715\n",
       "Positive affect                                             0.53377\n",
       "Freedom to make life choices                                0.49078\n",
       "Generosity                                                  0.14871\n",
       "year                                                        0.02165\n",
       "GINI index (World Bank estimate)                           -0.01376\n",
       "GINI index (World Bank estimate), average 2000-15          -0.09612\n",
       "Standard deviation of ladder by country-year               -0.10691\n",
       "Confidence in national government                          -0.12710\n",
       "Negative affect                                            -0.23617\n",
       "gini of household income reported in Gallup, by wp5-year   -0.26245\n",
       "Perceptions of corruption                                  -0.34256\n",
       "Standard deviation/Mean of ladder by country-year          -0.68513\n",
       "Name: label_life_ladder, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_corrs = round(df.corr(), 5)['label_life_ladder']\n",
    "high_corrs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** From the correlation list, we can see that relevant features might be features that has high correlation or high inverse correlation with the label, such as \"Log GDP per capita\", \"Healthy life expectancy at birth\", \"Social support\", \"Delivery Quality\", \"Democratic Quality\", \"Positive affect\", \"Democratic Quality\", and \"Perceptions of corruption\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The feature list I chose to keep includes: \"Log GDP per capita\", \"Healthy life expectancy at birth\", \"Social support\", \"Delivery Quality\", \"Democratic Quality\", \"Positive affect\", \"Democratic Quality\", and \"Perceptions of corruption\".\n",
    "2. The data preparation techniques that I will use to prepare my data for modeling include removing and replacing null values and outliers, feature selections based on high correlation or inverse correlation with the variable, and k-fold cross-validation to split data into training and testing sets.\n",
    "3. I'm implementing a Random Forest model and a Neural Network model to predict the life ladder score of each country based on the feature list above.\n",
    "4. I plan on using k-fold cross-validation to split and train my model on the given data set. While training, for the Random Forest Regressor, I would use Grid Search to find the best parameters/hyperparameters, train my model on the training data set, and pick the best parameter. Then I would compare the performance between the Logistic Regression and Neural Network model using evaluation metrics such as R2 and mean squared error, then take the best model. For the Neural Network model, because there are different ranges of data between the columns (shown below), I need to add a normalization layer to the neural network before the training and prediction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep data\n",
    "ft_use = [\"Log GDP per capita\", \"Healthy life expectancy at birth\", \"Social support\", \"Delivery Quality\", \"Democratic Quality\", \"Positive affect\", \"Democratic Quality\", \"Perceptions of corruption\"]\n",
    "df_use = df.drop(columns=['Life Ladder'])\n",
    "y = df_use['label_life_ladder']\n",
    "X = df_use[ft_use]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "param_grid = {\"max_depth\": [2**i for i in range(6)], \"min_samples_leaf\": [25*2**n for n in range(0,3)]}\n",
    "logistic_model = RandomForestRegressor()\n",
    "grid = GridSearchCV(logistic_model, cv=5, param_grid=param_grid)\n",
    "grid_search = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_leaf': 25}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_params = grid_search.best_params_\n",
    "best_rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(max_depth=best_rf_params[\"max_depth\"], min_samples_leaf=best_rf_params[\"min_samples_leaf\"])\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_labels = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse score for random forest: 0.30822720232219464\n",
      "r2 score for random forest: 0.7935080317982888\n"
     ]
    }
   ],
   "source": [
    "mse_rf_score = np.sqrt(mean_squared_error(y_test, best_rf_labels))\n",
    "r2_rf_score = r2_score(y_test, best_rf_labels)\n",
    "print(\"mse score for random forest: {mse}\".format(mse=mse_rf_score))\n",
    "print(\"r2 score for random forest: {r2}\".format(r2=r2_rf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range of column Log GDP per capita: [6.37739563, 11.77027607]\n",
      "range of column Healthy life expectancy at birth: [37.76647568, 76.53636169]\n",
      "range of column Social support: [0.29018417, 0.98734349]\n",
      "range of column Delivery Quality: [-2.144973993, 2.184724569]\n",
      "range of column Democratic Quality: [-2.448228121, 1.540097475]\n",
      "range of column Positive affect: [0.362497687, 0.943620622]\n",
      "range of column Democratic Quality: [-2.448228121, 1.540097475]\n",
      "range of column Perceptions of corruption: [0.035197988, 0.98327601]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for ft in ft_use:\n",
    "    print(\"range of column {col}: [{min_val}, {max_val}]\".format(col=ft, min_val=df[ft].min(), max_val=df[ft].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns' values need to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize features\n",
    "#create model\n",
    "nn_model = keras.Sequential()\n",
    "\n",
    "normalization_layer = keras.layers.BatchNormalization()\n",
    "nn_model.add(normalization_layer)\n",
    "\n",
    "input_layer = keras.layers.InputLayer(input_shape=(len(ft_use),), name='input')\n",
    "nn_model.add(input_layer)\n",
    "\n",
    "hidden_layer_1 = keras.layers.Dense(units=64, activation='relu')\n",
    "nn_model.add(hidden_layer_1)\n",
    "\n",
    "\n",
    "hidden_layer_2 = keras.layers.Dense(units=32, activation='relu')\n",
    "nn_model.add(hidden_layer_2)\n",
    "\n",
    "\n",
    "hidden_layer_3 = keras.layers.Dense(units=16, activation='relu')\n",
    "nn_model.add(hidden_layer_3)\n",
    "\n",
    "output_layer = keras.layers.Dense(units=1, name='output')\n",
    "nn_model.add(output_layer)\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(learning_rate=0.1)\n",
    "loss_fn = keras.losses.MeanSquaredLogarithmicError(\n",
    "    reduction=\"sum_over_batch_size\", name=\"mean_squared_error\"\n",
    ")\n",
    "\n",
    "nn_model.compile(optimizer=sgd_optimizer, loss=loss_fn, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.3974 - mse: 5.8554\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.0233 - mse: 0.9850\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.0138 - mse: 0.5613\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.0111 - mse: 0.4444\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.0092 - mse: 0.3659\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0085 - mse: 0.3420\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.0077 - mse: 0.3082\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.0073 - mse: 0.2928\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.0066 - mse: 0.2658\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0064 - mse: 0.2565\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.0060 - mse: 0.2433\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.0061 - mse: 0.2484\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.0057 - mse: 0.2280\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.0053 - mse: 0.2106\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0052 - mse: 0.2076\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0053 - mse: 0.2155\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0049 - mse: 0.1978\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.0051 - mse: 0.2036\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.0046 - mse: 0.1868\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0046 - mse: 0.1866\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.0044 - mse: 0.1770\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0043 - mse: 0.1739\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0041 - mse: 0.1664\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.0041 - mse: 0.1655\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.0042 - mse: 0.1675\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0038 - mse: 0.1548\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.0040 - mse: 0.1635\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0038 - mse: 0.1551\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0038 - mse: 0.1554\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0037 - mse: 0.1511\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0039 - mse: 0.1582\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0039 - mse: 0.1587\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0037 - mse: 0.1491\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.0035 - mse: 0.1405\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0035 - mse: 0.1407\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0036 - mse: 0.1455\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.0036 - mse: 0.1486\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.0037 - mse: 0.1495\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.0035 - mse: 0.1425\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0036 - mse: 0.1483\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.0032 - mse: 0.1319\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0035 - mse: 0.1421\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.0035 - mse: 0.1433\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.0033 - mse: 0.1333\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0033 - mse: 0.1360\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0034 - mse: 0.1398\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.0035 - mse: 0.1420\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0031 - mse: 0.1274\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0032 - mse: 0.1284\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.0032 - mse: 0.1315\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0033 - mse: 0.1332\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.0031 - mse: 0.1264\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0032 - mse: 0.1305\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.0031 - mse: 0.1264\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.0031 - mse: 0.1280\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.0032 - mse: 0.1286\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0032 - mse: 0.1308\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0033 - mse: 0.1327\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.0033 - mse: 0.1331\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.0032 - mse: 0.1291\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0031 - mse: 0.1263\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.0030 - mse: 0.1214\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.0031 - mse: 0.1243\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.0030 - mse: 0.1230\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0031 - mse: 0.1264\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0030 - mse: 0.1205\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0030 - mse: 0.1240\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0032 - mse: 0.1301\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.0030 - mse: 0.1248\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.0030 - mse: 0.1225\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0029 - mse: 0.1192\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0032 - mse: 0.1302\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0031 - mse: 0.1254\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.0029 - mse: 0.1191\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.0034 - mse: 0.1378\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.0030 - mse: 0.1207\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.0030 - mse: 0.1220\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.0029 - mse: 0.1173\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.0031 - mse: 0.1245\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.0030 - mse: 0.1209\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.0032 - mse: 0.1316\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.0029 - mse: 0.1187\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.0029 - mse: 0.1200\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.0030 - mse: 0.1212\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.0029 - mse: 0.1188\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.0030 - mse: 0.1222\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0028 - mse: 0.1138\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.0029 - mse: 0.1185\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.0028 - mse: 0.1155\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0030 - mse: 0.1202\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.0031 - mse: 0.1261\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.0028 - mse: 0.1157\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.0030 - mse: 0.1204\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.0030 - mse: 0.1242\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.0030 - mse: 0.1204\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.0030 - mse: 0.1215\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.0030 - mse: 0.1214\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.0029 - mse: 0.1158\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.0031 - mse: 0.1257\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.0028 - mse: 0.1151\n",
      "Elapsed time: 2.36s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 # Number of epochs\n",
    "t0 = time.time() # start time\n",
    "history = nn_model.fit(X_train, y_train, epochs=num_epochs, verbose=1)# YOUR CODE HERE \n",
    "t1 = time.time() # stop time\n",
    "print('Elapsed time: %.2fs' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_label_predictions = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse score for random forest: 0.3158557676196155\n",
      "r2 score for random forest: 0.7831602697169349\n"
     ]
    }
   ],
   "source": [
    "mse_rf_score = np.sqrt(mean_squared_error(y_test, nn_label_predictions))\n",
    "r2_rf_score = r2_score(y_test, nn_label_predictions)\n",
    "print(\"mse score for random forest: {mse}\".format(mse=mse_rf_score))\n",
    "print(\"r2 score for random forest: {r2}\".format(r2=r2_rf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** From the 2 evaluation scores, we can see that the 2 models are similar and comparable in terms of the Mean Squared Error score and the R2 score. Therefore, we can conclude that the Random Forest Regressor is preferable over the Neural Network because it has a faster time to train and predict. The Neural Network model has also been tested with different epoch numbers, at 10, the scores are 0.46 and 0.54 for MSE and R2, and at 1, the scores are 10.3 and -229.53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
